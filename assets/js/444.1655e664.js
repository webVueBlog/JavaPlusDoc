(window.webpackJsonp=window.webpackJsonp||[]).push([[444],{1281:function(a,e,t){"use strict";t.r(e);var r=t(1),o=Object(r.a)({},(function(){var a=this,e=a._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("blockquote",[e("p",[a._v("点击勘误"),e("a",{attrs:{href:"https://github.com/webVueBlog/JavaPlusDoc/issues",target:"_blank",rel:"noopener noreferrer"}},[a._v("issues"),e("OutboundLink")],1),a._v("，哪吒感谢大家的阅读")])]),a._v(" "),e("img",{attrs:{align:"right",width:"100",src:"https://cdn.jsdelivr.net/gh/YunYouJun/yun/images/yun-alpha-compressed.png"}}),a._v(" "),e("h2",{attrs:{id:"权威指南kafka"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#权威指南kafka"}},[a._v("#")]),a._v(" 权威指南kafka")]),a._v(" "),e("p",[a._v("Kafka 就是为了解决上述问题而设计的一款基于发布与订阅的消息系统。它一般被称为 “分布式提交日志”或者“分布式流平台”。文件系统或数据库提交日志用来提供所有事务 的持久记录，通过重放这些日志可以重建系统的状态。同样地，Kafka 的数据是按照一定 顺序持久化保存的，可以按需读取。此外，Kafka 的数据分布在整个系统里，具备数据故 障保护和性能伸缩能力。")]),a._v(" "),e("p",[a._v("消息和批次")]),a._v(" "),e("p",[a._v("消息和批次 Kafka 的数据单元被称为消息。如果你在使用 Kafka 之前已经有数据库使用经验，那么可 以把消息看成是数据库里的一个“数据行”或一条“记录”。消息由字节数组组成，所以 对于 Kafka 来说，消息里的数据没有特别的格式或含义。消息可以有一个可选的元数据， 也就是键。键也是一个字节数组，与消息一样，对于 Kafka 来说也没有特殊的含义。当消 息以一种可控的方式写入不同的分区时，会用到键。最简单的例子就是为键生成一个一致 性散列值，然后使用散列值对主题分区数进行取模，为消息选取分区。这样可以保证具有 相同键的消息总是被写到相同的分区上。")]),a._v(" "),e("p",[a._v("为了提高效率，消息被分批次写入 Kafka。批次就是一组消息，这些消息属于同一个主题 和分区。如果每一个消息都单独穿行于网络，会导致大量的网络开销，把消息分成批次传 输可以减少网络开销。不过，这要在时间延迟和吞吐量之间作出权衡：批次越大，单位时 间内处理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升 数据的传输和存储能力，但要做更多的计算处理。")]),a._v(" "),e("p",[a._v("模式")]),a._v(" "),e("p",[a._v("对于 Kafka 来说，消息不过是晦涩难懂的字节数组，所以有人建议用一些额外的结构来 定义消息内容，让它们更易于理解。根据应用程序的需求，消息模式（schema）有许多 可用的选项。像 JSON 和 XML 这些简单的系统，不仅易用，而且可读性好。不过，它们 缺乏强类型处理能力，不同版本之间的兼容性也不是很好。Kafka 的许多开发者喜欢使用 Apache Avro，它最初是为 Hadoop 开发的一款序列化框架。Avro 提供了一种紧凑的序列化 格式，模式和消息体是分开的，当模式发生变化时，不需要重新生成代码；它还支持强类 型和模式进化，其版本既向前兼容，也向后兼容。 数据格式的一致性对于 Kafka 来说很重要，它消除了消息读写操作之间的耦合性。如果读 写操作紧密地耦合在一起，消息订阅者需要升级应用程序才能同时处理新旧两种数据格 式。在消息订阅者升级了之后，消息发布者才能跟着升级，以便使用新的数据格式。新的 应用程序如果需要使用数据，就要与消息发布者发生耦合，导致开发者需要做很多繁杂 的工作。定义良好的模式，并把它们存放在公共仓库，可以方便我们理解 Kafka 的消息结 构。")]),a._v(" "),e("p",[a._v("集群里的分区复制")]),a._v(" "),e("p",[a._v("保留消息（在一定期限内）是 Kafka 的一个重要特性。Kafka broker 默认的消息保留策略 是这样的：要么保留一段时间（比如 7 天），要么保留到消息达到一定大小的字节数（比 如 1GB）。当消息数量达到这些上限时，旧消息就会过期并被删除，所以在任何时刻，可 用消息的总量都不会超过配置参数所指定的大小。主题可以配置自己的保留策略，可以将 消息保留到不再使用它们为止。例如，用于跟踪用户活动的数据可能需要保留几天，而应 用程序的度量指标可能只需要保留几个小时。可以通过配置把主题当作紧凑型日志，只有 最后一个带有特定键的消息会被保留下来。这种情况对于变更日志类型的数据来说比较适 用，因为人们只关心最后时刻发生的那个变更。")]),a._v(" "),e("p",[a._v("多集群")]),a._v(" "),e("p",[a._v("随着 Kafka 部署数量的增加，基于以下几点原因，最好使用多个集群。 • 数据类型分离 • 安全需求隔离 • 多数据中心（灾难恢复）")]),a._v(" "),e("p",[a._v("如果使用多个数据中心，就需要在它们之间复制消息。这样，在线应用程序才可以访问到 多个站点的用户活动信息。例如，如果一个用户修改了他们的资料信息，不管从哪个数据 中心都应该能看到这些改动。或者多个站点的监控数据可以被聚集到一个部署了分析程序 和告警系统的中心位置。不过，Kafka 的消息复制机制只能在单个集群里进行，不能在多 个集群之间进行。")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/604216dc9e724fa9877219f57b6a344a~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=DpbFuImGWQqWUKJ21gDTJLy0Z6U%3D",alt:""}})]),a._v(" "),e("p",[a._v("为什么选择Kafka")]),a._v(" "),e("p",[a._v("基于发布与订阅的消息系统那么多，为什么 Kafka 会是一个更好的选择呢？")]),a._v(" "),e("p",[a._v("多个生产者 Kafka 可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题。所以它很 适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。例如，一个包含了多 个微服务的网站，可以为页面视图创建一个单独的主题，所有服务都以相同的消息格式向 该主题写入数据。消费者应用程序会获得统一的页面视图，而无需协调来自不同生产者的 数据流。")]),a._v(" "),e("p",[a._v("多个消费者")]),a._v(" "),e("p",[a._v("除了支持多个生产者外，Kafka 也支持多个消费者从一个单独的消息流上读取数据，而且 消费者之间互不影响。这与其他队列系统不同，其他队列系统的消息一旦被一个客户端读 取，其他客户端就无法再读取它。另外，多个消费者可以组成一个群组，它们共享一个消 息流，并保证整个群组对每个给定的消息只处理一次。")]),a._v(" "),e("p",[a._v("基于磁盘的数据存储")]),a._v(" "),e("p",[a._v("Kafka 不仅支持多个消费者，还允许消费者非实时地读取消息，这要归功于 Kafka 的数据 保留特性。消息被提交到磁盘，根据设置的保留规则进行保存。每个主题可以设置单独的 保留规则，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。消费者可能 会因为处理速度慢或突发的流量高峰导致无法及时读取消息，而持久化数据可以保证数据 不会丢失。消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵 塞在生产者端。消费者可以被关闭，但消息会继续保留在 Kafka 里。消费者可以从上次中 断的地方继续处理消息。")]),a._v(" "),e("p",[a._v("伸缩性")]),a._v(" "),e("p",[a._v("为了能够轻松处理大量数据，Kafka 从一开始就被设计成一个具有灵活伸缩性的系统。用 户在开发阶段可以先使用单个 broker，再扩展到包含 3 个 broker 的小型开发集群，然后随 着数据量不断增长，部署到生产环境的集群可能包含上百个 broker。对在线集群进行扩展 丝毫不影响整体系统的可用性。也就是说，一个包含多个 broker 的集群，即使个别 broker 失效，仍然可以持续地为客户提供服务。要提高集群的容错能力，需要配置较高的复制系 数。")]),a._v(" "),e("p",[a._v("高性能")]),a._v(" "),e("p",[a._v("Kafka 成为了一个高性能的发布与订阅消息系统。通过横向扩展 生产者、消费者和 broker，Kafka 可以轻松处理巨大的消息流。在处理大量数据的同时， 它还能保证亚秒级的消息延迟。")]),a._v(" "),e("p",[a._v("数据生态系统")]),a._v(" "),e("p",[a._v("已经有很多应用程序加入到了数据处理的大军中。我们定义了输入和应用程序，负责生成 数据或者把数据引入系统。我们定义了输出，它们可以是度量指标、报告或者其他类型的 数据。我们创建了一些循环，使用一些组件从系统读取数据，对读取的数据进行处理，然 后把它们导到数据基础设施上，以备不时之需。数据类型可以多种多样，每一种数据类型 可以有不同的内容、大小和用途。 Kafka 为数据生态系统带来了循环系统")]),a._v(" "),e("p",[a._v("可以根据业务 需要添加或移除组件，因为生产者不再关心谁在使用数据，也不关心有多少个消费者。")]),a._v(" "),e("p",[a._v("使用场景")]),a._v(" "),e("ol",[e("li",[e("p",[a._v("活动跟踪 Kafka 最初的使用场景是跟踪用户的活动。网站用户与前端应用程序发生交互，前端应用 程序生成用户活动相关的消息。这些消息可以是一些静态的信息，比如页面访问次数和点 击量，也可以是一些复杂的操作，比如添加用户资料。这些消息被发布到一个或多个主题 上，由后端应用程序负责读取。这样，我们就可以生成报告，为机器学习系统提供数据， 更新搜索结果，或者实现其他更多的功能。")])]),a._v(" "),e("li",[e("p",[a._v("传递消息")])])]),a._v(" "),e("p",[a._v("Kafka 的另一个基本用途是传递消息。应用程序向用户发送通知（比如邮件）就是通过传 递消息来实现的。这些应用程序组件可以生成消息，而不需要关心消息的格式，也不需要 关心消息是如何被发送的。一个公共应用程序会读取这些消息，对它们进行处理： • 格式化消息（也就是所谓的装饰）； • 将多个消息放在同一个通知里发送； • 根据用户配置的首选项来发送数据。 使用公共组件的好处在于，不需要在多个应用程序上开发重复的功能，而且可以在公共组 件上做一些有趣的转换，比如把多个消息聚合成一个单独的通知，而这些工作是无法在其 他地方完成的。")]),a._v(" "),e("ol",{attrs:{start:"3"}},[e("li",[a._v("度量指标和日志记录")])]),a._v(" "),e("p",[a._v("Kafka 也可以用于收集应用程序和系统度量指标以及日志。Kafka 支持多个生产者的特性在 这个时候就可以派上用场。应用程序定期把度量指标发布到 Kafka 主题上，监控系统或告 警系统读取这些消息。Kafka 也可以用在像 Hadoop 这样的离线系统上，进行较长时间片段 的数据分析，比如年度增长走势预测。日志消息也可以被发布到 Kafka 主题上，然后被路 由到专门的日志搜索系统（比如 Elasticsearch）或安全分析应用程序。更改目标系统（比 如日志存储系统）不会影响到前端应用或聚合方法，这是 Kafka 的另一个优点。")]),a._v(" "),e("ol",{attrs:{start:"4"}},[e("li",[a._v("提交日志")])]),a._v(" "),e("p",[a._v("Kafka 的基本概念来源于提交日志，所以使用 Kafka 作为提交日志是件顺理成章的事。我 们可以把数据库的更新发布到 Kafka 上，应用程序通过监控事件流来接收数据库的实时更 新。这种变更日志流也可以用于把数据库的更新复制到远程系统上，或者合并多个应用程 序的更新到一个单独的数据库视图上。数据持久化为变更日志提供了缓冲区，也就是说， 如果消费者应用程序发生故障，可以通过重放这些日志来恢复系统状态。另外，紧凑型日 志主题只为每个键保留一个变更数据，所以可以长时间使用，不需要担心消息过期问题。")]),a._v(" "),e("h1",{attrs:{id:"安装kafka"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#安装kafka"}},[a._v("#")]),a._v(" 安装Kafka")]),a._v(" "),e("p",[a._v("介绍如何安装和运行 Kafka，包括如何设置 Zookeeper（Kafka 使用 Zookeeper 保 存 Broker 的元数据），还会介绍 Kafka 的基本配置，以及如何为 Kafka 选择合适的硬件")]),a._v(" "),e("h2",{attrs:{id:"安装java"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#安装java"}},[a._v("#")]),a._v(" 安装Java")]),a._v(" "),e("p",[a._v("在安装 Zookeeper 和 Kafka 之前，需要先安装 Java 环境。这里推荐安装 Java 8，可以使用 系统自带的安装包，也可以直接从 java.com 网站下载。虽然运行 Zookeeper 和 Kafka 只需 要 Java 运行时版本，但也可以安装完整的 JDK，以备不时之需。假设 JDK 8 update 51 已 经安装在 /usr/java/jdk1.8.0_51 目录下，其他软件的安装都是基于这个前提进行的。")]),a._v(" "),e("h2",{attrs:{id:"安装zookeeper"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#安装zookeeper"}},[a._v("#")]),a._v(" 安装Zookeeper")]),a._v(" "),e("p",[a._v("Kafka 使 用 Zookeeper 保 存 集 群 的 元 数 据 信 息 和 消 费 者 信 息。Kafka 发行版自带了 Zookeeper，可以直接从脚本启动，不过安装一个完整版的 Zookeeper 也并不费劲。")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/49778b4298c5438db2c793a75705155a~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=SWe%2FL850B%2BaWYtRsQSLqFGLsj3w%3D",alt:""}})]),a._v(" "),e("p",[a._v("Zookeeper 的 3.4.6 稳定版已经在 Kafka 上做过全面测试，可以从 apache.org 下载该版本的 Zookeeper："),e("a",{attrs:{href:"http://bit.ly/2sDWSgJ%E3%80%82",target:"_blank",rel:"noopener noreferrer"}},[a._v("http://bit.ly/2sDWSgJ。"),e("OutboundLink")],1)]),a._v(" "),e("ol",[e("li",[a._v("单机服务 下面的例子演示了如何使用基本的配置安装 Zookeeper，安装目录为 /usr/local/zookeeper， 数据目录为 /var/lib/zookeeper。")])]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/f4b63ca19fff4c2a8a068981d0ce018e~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=GZkJfmwQ3hXjS5CERLLn4h3b9tQ%3D",alt:""}})]),a._v(" "),e("p",[a._v("现在可以连到 Zookeeper 端口上，通过发送四字命令 srvr 来验证 Zookeeper 是否安装正确。")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/1645c7812d784b23a673dbefcd50050e~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=p1NRffBJJgj9DTKW1QGduj4PmMA%3D",alt:""}})]),a._v(" "),e("p",[a._v("Zookeeper 群组（Ensemble）")]),a._v(" "),e("p",[a._v("Zookeeper 集群被称为群组。Zookeeper 使用的是一致性协议，所以建议每个群组里应该包 含奇数个节点（比如 3 个、5 个等），因为只有当群组里的大多数节点（也就是法定人数） 处于可用状态，Zookeeper 才能处理外部的请求。也就是说，如果你有一个包含 3 个节点 的群组，那么它允许一个节点失效。如果群组包含 5 个节点，那么它允许 2 个节点失效。")]),a._v(" "),e("h2",{attrs:{id:"群组节点个数的选择"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#群组节点个数的选择"}},[a._v("#")]),a._v(" 群组节点个数的选择")]),a._v(" "),e("p",[a._v("假设有一个包含 5 个节点的群组，如果要对群组做一些包括更换节点在内的 配置更改，需要依次重启每一个节点。如果你的群组无法容忍多个节点失 效，那么在进行群组维护时就会存在风险。不过，也不建议一个群组包含超 过 7 个节点，因为 Zookeeper 使用了一致性协议，节点过多会降低整个群组 的性能。")]),a._v(" "),e("p",[a._v("群组需要有一些公共配置，上面列出了所有服务器的清单，并且每个服务器还要在数据 目录中创建一个 myid 文件，用于指明自己的 ID。如果群组里服务器的机器名是 zoo1. example.com、zoo2.example.com、zoo3.example.com，那么配置文件可能是这样的：")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/71c5db85c2c44a1dade0ea617dc246b4~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=12oXstLknt%2Bx9kcWMAolMyShIpo%3D",alt:""}})]),a._v(" "),e("p",[a._v("在这个配置中，initLimit 表示用于在从节点与主节点之间建立初始化连接的时间上限， syncLimit 表示允许从节点与主节点处于不同步状态的时间上限。这两个值都是 tickTime 的 倍数，所以 initLimit 是 20*2000ms，也就是 40s。配置里还列出了群组中所有服务器的地 址。服务器地址遵循 server.X=hostname:peerPort:leaderPort 格式，各个参数说明如下：")]),a._v(" "),e("p",[a._v("X 服务器的 ID，它必须是一个整数，不过不一定要从 0 开始，也不要求是连续的；")]),a._v(" "),e("p",[a._v("hostname 服务器的机器名或 IP 地址；")]),a._v(" "),e("p",[a._v("peerPort 用于节点间通信的 TCP 端口；")]),a._v(" "),e("p",[a._v("leaderPort 用于首领选举的 TCP 端口。")]),a._v(" "),e("p",[a._v("客户端只需要通过 clientPort 就能连接到群组，而群组节点间的通信则需要同时用到这 3 个 端口（peerPort、leaderPort、clientPort）。")]),a._v(" "),e("p",[a._v("除了公共的配置文件外，每个服务器都必须在 data Dir 目录中创建一个叫作 myid 的文件， 文件里要包含服务器 ID，这个 ID 要与配置文件里配置的 ID 保持一致。完成这些步骤后， 就可以启动服务器，让它们彼此间进行通信了。")]),a._v(" "),e("p",[a._v("配置好 Java 和 Zookeeper 之后，接下来就可以安装 Kafka 了。可以从 "),e("a",{attrs:{href:"http://kafka.apache",target:"_blank",rel:"noopener noreferrer"}},[a._v("http://kafka.apache"),e("OutboundLink")],1),a._v(". org/downloads.html 下载最新版本的 Kafka。")]),a._v(" "),e("p",[a._v("Kafka 的版本是 0.9.0.1，对 应的 Scala 版本是 2.11.0。 下面的例子将 Kafka 安装在 /usr/local/kafka 目录下，使用之前配置好的 Zookeeper，并把消 息日志保存在 /tmp/kafka-logs 目录下。")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/032d1756236f41329203c53d0fe2cdde~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=AN8eoS9TS4QnRl9ccezVLFEibc4%3D",alt:""}})]),a._v(" "),e("p",[a._v("一旦 Kafka 创建完毕，就可以对这个集群做一些简单的操作来验证它是否安装正确，比如 创建一个测试主题，发布一些消息，然后读取它们。 创建并验证主题：")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/d548ce097900468380e56177932464c9~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=4mtCPxhGA4MafXD8%2FFcRyypvEEE%3D",alt:""}})]),a._v(" "),e("p",[a._v("往测试主题上发布消息：")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/c54edd0e4923457ba036c0c1cde1861c~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=5dxDMFt0TzhtmKp18zgaVZJ4SQs%3D",alt:""}})]),a._v(" "),e("p",[a._v("从测试主题上读取消息")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/77106651467c40a9a4df6af7a232b8d7~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=DMHFHXvIlPyoJFGpjQcE10jNcMY%3D",alt:""}})]),a._v(" "),e("p",[a._v("Kafka 发行包里自带的配置样本可以用来安装单机服务，但并不能满足大多数安装场景的 要求。Kafka 有很多配置选项，涉及安装和调优的方方面面。不过大多数调优选项可以使 用默认配置，除非你对调优有特别的要求。")]),a._v(" "),e("h2",{attrs:{id:"broker-id"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#broker-id"}},[a._v("#")]),a._v(" broker.id")]),a._v(" "),e("p",[a._v("每个 broker 都需要有一个标识符，使用 broker.id 来表示。它的默认值是 0，也可以被设置 成其他任意整数。这个值在整个 Kafka 集群里必须是唯一的。这个值可以任意选定，如果 出于维护的需要，可以在服务器节点间交换使用这些 ID。建议把它们设置成与机器名具有 相关性的整数，这样在进行维护时，将 ID 号映射到机器名就没那么麻烦了。例如，如果 机器名包含唯一性的数字（比如 host1.example.com、host2.example.com），那么用这些数字 来设置 broker.id 就再好不过了。")]),a._v(" "),e("h2",{attrs:{id:"port"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#port"}},[a._v("#")]),a._v(" port")]),a._v(" "),e("p",[a._v("如果使用配置样本来启动 Kafka，它会监听 9092 端口。修改 port 配置参数可以把它设置 成其他任意可用的端口。要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 Kafka，不过不建议这么做。")]),a._v(" "),e("h2",{attrs:{id:"zookeeper-connect"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#zookeeper-connect"}},[a._v("#")]),a._v(" zookeeper.connect")]),a._v(" "),e("p",[a._v("用于保存 broker 元数据的 Zookeeper 地址是通过 zookeeper.connect 来 指 定 的。 localhost:2181 表示这个 Zookeeper 是运行在本地的 2181 端口上。该配置参数是用冒号分 隔的一组 hostname:port/path 列表，每一部分的含义如下：")]),a._v(" "),e("p",[a._v("• hostname 是 Zookeeper 服务器的机器名或 IP 地址；")]),a._v(" "),e("p",[a._v("• port 是 Zookeeper 的客户端连接端口；")]),a._v(" "),e("p",[a._v("• /path 是可选的 Zookeeper 路径，作为 Kafka 集群的 chroot 环境。")]),a._v(" "),e("p",[a._v("如果不指定，默认使用 根路径。")]),a._v(" "),e("p",[a._v("如果指定的 chroot 路径不存在，broker 会在启动的时候创建它。")]),a._v(" "),e("h2",{attrs:{id:"为什么使用-chroot"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用-chroot"}},[a._v("#")]),a._v(" 为什么使用 chroot")]),a._v(" "),e("p",[a._v("路径 在 Kafka 集群里使用 chroot 路径是一种最佳实践。Zookeeper 群组可以共享 给其他应用程序，即使还有其他 Kafka 集群存在，也不会产生冲突。最好是 在配置文件里指定一组 Zookeeper 服务器，用分号把它们隔开。一旦有一个 Zookeeper 服务器宕机，broker 可以连接到 Zookeeper 群组的另一个节点上。")]),a._v(" "),e("h2",{attrs:{id:"log-dirs"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#log-dirs"}},[a._v("#")]),a._v(" log.dirs")]),a._v(" "),e("p",[a._v("Kafka 把所有消息都保存在磁盘上，存放这些日志片段的目录是通过 log.dirs 指定的。它是 一组用逗号分隔的本地文件系统路径。如果指定了多个路径，那么 broker 会根据“最少使 用”原则，把同一个分区的日志片段保存到同一个路径下。要注意，broker 会往拥有最少 数目分区的路径新增分区，而不是往拥有最小磁盘空间的路径新增分区。")]),a._v(" "),e("h2",{attrs:{id:"num-recovery-threads-per-data-dir"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#num-recovery-threads-per-data-dir"}},[a._v("#")]),a._v(" num.recovery.threads.per.data.dir")]),a._v(" "),e("p",[a._v("对于如下 3 种情况，Kafka 会使用可配置的线程池来处理日志片段：")]),a._v(" "),e("p",[a._v("• 服务器正常启动，用于打开每个分区的日志片段；")]),a._v(" "),e("p",[a._v("• 服务器崩溃后重启，用于检查和截短每个分区的日志片段；")]),a._v(" "),e("p",[a._v("• 服务器正常关闭，用于关闭日志片段。")]),a._v(" "),e("p",[a._v("默认情况下，每个日志目录只使用一个线程。因为这些线程只是在服务器启动和关闭时会 用到，所以完全可以设置大量的线程来达到并行操作的目的。特别是对于包含大量分区的 服务器来说，一旦发生崩溃，在进行恢复时使用并行操作可能会省下数小时的时间。设置 此参数时需要注意，所配置的数字对应的是 log.dirs 指定的单个日志目录。也就是说，如 果 num.recovery.threads.per.data.dir 被设为 8，并且 log.dir 指定了 3 个路径，那么总 共需要 24 个线程。")]),a._v(" "),e("h2",{attrs:{id:"auto-create-topics-enable"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#auto-create-topics-enable"}},[a._v("#")]),a._v(" auto.create.topics.enable")]),a._v(" "),e("p",[a._v("默认情况下，Kafka 会在如下几种情形下自动创建主题：")]),a._v(" "),e("p",[a._v("• 当一个生产者开始往主题写入消息时；")]),a._v(" "),e("p",[a._v("• 当一个消费者开始从主题读取消息时；")]),a._v(" "),e("p",[a._v("• 当任意一个客户端向主题发送元数据请求时。")]),a._v(" "),e("p",[a._v("很多时候，这些行为都是非预期的。而且，根据 Kafka 协议，如果一个主题不先被创建， 根本无法知道它是否已经存在。如果显式地创建主题，不管是手动创建还是通过其他配置 系统来创建，都可以把 auto.create.topics.enable 设为 false。")]),a._v(" "),e("h1",{attrs:{id:"主题的默认配置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#主题的默认配置"}},[a._v("#")]),a._v(" 主题的默认配置")]),a._v(" "),e("p",[a._v("Kafka 为新创建的主题提供了很多默认配置参数。可以通过管理工具")]),a._v(" "),e("h2",{attrs:{id:"使用主题配置覆盖-override"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#使用主题配置覆盖-override"}},[a._v("#")]),a._v(" 使用主题配置覆盖（override）")]),a._v(" "),e("p",[a._v("之前的 Kafka 版本允许主题覆盖服务器的默认配置，包括 log.retention. hours.per.topic、log.retention.bytes.per.topic 和 log.seg ment.bytes. per.topic 这几个参数。新版本不再支持这些参数，而且如果要对参数进行 覆盖，需要使用管理工具。")]),a._v(" "),e("h2",{attrs:{id:"_1-num-partitions-num-partitions"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-num-partitions-num-partitions"}},[a._v("#")]),a._v(" 1. num.partitions num.partitions")]),a._v(" "),e("p",[a._v("参数指定了新创建的主题将包含多少个分区。如果启用了主题自动创建功 能（该功能默认是启用的），主题分区的个数就是该参数指定的值。该参数的默认值是 1。 要注意，我们可以增加主题分区的个数，但不能减少分区的个数。所以，如果要让一个主 题的分区个数少于 num.partitions 指定的值，需要手动创建该主题")]),a._v(" "),e("p",[a._v("Kafka 集群通过分区对主题进行横向扩展，所以当有新的 broker 加入 集群时，可以通过分区个数来实现集群的负载均衡。当然，这并不是说，在存在多个主题 的情况下（它们分布在多个 broker 上），为了能让分区分布到所有 broker 上，主题分区的 个数必须要大于 broker 的个数。不过，拥有大量消息的主题如果要进行负载分散，就需要 大量的分区。")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/84d2be881b4243bdaf9e8ef6c1d4d032~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5oiR5piv5ZOq5ZCS:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTQ1MTAxMTA4MTI0OTE3NSJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1738338194&x-orig-sign=5PDw1OLKduoSByOKGhkiWxoMXPc%3D",alt:""}})]),a._v(" "),e("h2",{attrs:{id:"_2-log-retention-ms"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-log-retention-ms"}},[a._v("#")]),a._v(" 2. log.retention.ms")]),a._v(" "),e("p",[a._v("Kafka 通常根据时间来决定数据可以被保留多久。默认使用 log.retention.hours 参数来配 置时间，默认值为 168 小时，也就是一周。除此以外，还有其他两个参数 log.retention. minutes 和 log.retention.ms。这 3 个参数的作用是一样的，都是决定消息多久以后会被删 除，不过还是推荐使用 log.retention.ms。如果指定了不止一个参数，Kafka 会优先使用 具有最小值的那个参数。")]),a._v(" "),e("h2",{attrs:{id:"根据时间保留数据和最后修改时间"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#根据时间保留数据和最后修改时间"}},[a._v("#")]),a._v(" 根据时间保留数据和最后修改时间")]),a._v(" "),e("p",[a._v("根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现 的。一般来说，最后修改时间指的就是日志片段的关闭时间，也就是文件里 最后一个消息的时间戳。不过，如果使用管理工具在服务器间移动分区，最 后修改时间就不准确了。时间误差可能导致这些分区过多地保留数据。")]),a._v(" "),e("h2",{attrs:{id:"_3-log-retention-bytes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-log-retention-bytes"}},[a._v("#")]),a._v(" 3. log.retention.bytes")]),a._v(" "),e("p",[a._v("另一种方式是通过保留的消息字节数来判断消息是否过期。它的值通过参数 log. retention.bytes 来指定，作用在每一个分区上。也就是说，如果有一个包含 8 个分区的主 题，并且 log.retention.bytes 被设为 1GB，那么这个主题最多可以保留 8GB 的数据。所 以，当主题的分区个数增加时，整个主题可以保留的数据也随之增加。")]),a._v(" "),e("h2",{attrs:{id:"_4-log-segment-bytes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-log-segment-bytes"}},[a._v("#")]),a._v(" 4. log.segment.bytes")]),a._v(" "),e("p",[a._v("以上的设置都作用在日志片段上，而不是作用在单个消息上。当消息到达 broker 时，它 们被追加到分区的当前日志片段上。当日志片段大小达到 log.segment.bytes 指定的上限 （默认是 1GB）时，当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志 片段被关闭，就开始等待过期。这个参数的值越小，就会越频繁地关闭和分配新文件，从 而降低磁盘写入的整体效率。")]),a._v(" "),e("p",[a._v("如果主题的消息量不大，那么如何调整这个参数的大小就变得尤为重要。例如，如果一个 主题每天只接收 100MB 的消息，而 log.segment.bytes 使用默认设置，那么需要 10 天时 间才能填满一个日志片段。因为在日志片段被关闭之前消息是不会过期的，所以如果 log. retention.ms 被设为 604 800 000（也就是 1 周），那么日志片段最多需要 17 天才会过期。 这是因为关闭日志片段需要 10 天的时间，而根据配置的过期时间，还需要再保留 7 天时 间（要等到日志片段里的最后一个消息过期才能被删除）。")]),a._v(" "),e("h2",{attrs:{id:"使用时间戳获取偏移量"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#使用时间戳获取偏移量"}},[a._v("#")]),a._v(" 使用时间戳获取偏移量")]),a._v(" "),e("p",[a._v("日志片段的大小会影响使用时间戳获取偏移量。在使用时间戳获取日志偏移 量时，Kafka 会检查分区里最后修改时间大于指定时间戳的日志片段（已经 被关闭的），该日志片段的前一个文件的最后修改时间小于指定时间戳。然 后，Kafka 返回该日志片段（也就是文件名）开头的偏移量。对于使用时间 戳获取偏移量的操作来说，日志片段越小，结果越准确。")]),a._v(" "),e("h2",{attrs:{id:"_5-log-segment-ms"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-log-segment-ms"}},[a._v("#")]),a._v(" 5. log.segment.ms")]),a._v(" "),e("p",[a._v("另一个可以控制日志片段关闭时间的参数是 log.segment.ms，它指定了多长时间之后日 志片段会被关闭。就像 log.retention.bytes 和 log.retention.ms 这两个参数一样，log. segment.bytes 和 log.retention.ms 这两个参数之间也不存在互斥问题。日志片段会在大 小或时间达到上限时被关闭，就看哪个条件先得到满足。默认情况下，log.segment.ms 没 有设定值，所以只根据大小来关闭日志片段。")]),a._v(" "),e("h2",{attrs:{id:"基于时间的日志片段对磁盘性能的影响"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基于时间的日志片段对磁盘性能的影响"}},[a._v("#")]),a._v(" 基于时间的日志片段对磁盘性能的影响")]),a._v(" "),e("p",[a._v("在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性 能的影响。如果多个分区的日志片段永远不能达到大小的上限，就会发生这 种情况，因为 broker 在启动之后就开始计算日志片段的过期时间，对于那些 数据量小的分区来说，日志片段的关闭操作总是同时发生。")]),a._v(" "),e("h2",{attrs:{id:"_6-message-max-bytes-broker"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_6-message-max-bytes-broker"}},[a._v("#")]),a._v(" 6. message.max.bytes broker")]),a._v(" "),e("p",[a._v("通过设置 message.max.bytes 参数来限制单个消息的大小，默认值是 1 000 000，也 就是 1MB。如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误信息。跟其他与字节相关的配置参数一样，该参数指的是压缩后的消息 大小，也就是说，只要压缩后的消息小于 message.max.bytes 指定的值，消息的实际大小 可以远大于这个值。")]),a._v(" "),e("p",[a._v("这个值对性能有显著的影响。值越大，那么负责处理网络连接和请求的线程就需要花越多 的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响 IO 吞吐量。")]),a._v(" "),e("h2",{attrs:{id:"在服务端和客户端之间协调消息大小的配置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#在服务端和客户端之间协调消息大小的配置"}},[a._v("#")]),a._v(" 在服务端和客户端之间协调消息大小的配置")]),a._v(" "),e("p",[a._v("消费者客户端设置的 fetch.message.max.bytes 必须与服务器端设置的消息 大小进行协调。如果这个值比 message.max.bytes 小，那么消费者就无法读 取比较大的消息，导致出现消费者被阻塞的情况。在为集群里的 broker 配置 replica.fetch.max.bytes 参数时，也遵循同样的原则。")]),a._v(" "),e("h1",{attrs:{id:"硬件的选择"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#硬件的选择"}},[a._v("#")]),a._v(" 硬件的选择")]),a._v(" "),e("p",[a._v("磁盘吞吐量和容量、内存、网络和 CPU。")]),a._v(" "),e("h2",{attrs:{id:"磁盘吞吐量"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#磁盘吞吐量"}},[a._v("#")]),a._v(" 磁盘吞吐量")]),a._v(" "),e("p",[a._v("生产者客户端的性能直接受到服务器端磁盘吞吐量的影响。生产者生成的消息必须被提交 到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认消 息已经成功提交为止。也就是说，磁盘写入速度越快，生成消息的延迟就越低。 在考虑硬盘类型对磁盘吞吐量的影响时，是选择传统的机械硬盘（HDD）还是固态硬盘 （SSD），我们可以很容易地作出决定。固态硬盘的查找和访问速度都很快，提供了最好的 性能。机械硬盘更便宜，单块硬盘容量也更大。在同一个服务器上使用多个机械硬盘，可 以设置多个数据目录，或者把它们设置成磁盘阵列，这样可以提升机械硬盘的性能。其他 方面的因素，比如磁盘特定的技术（串行连接存储技术或 SATA），或者磁盘控制器的质 量，都会影响吞吐量。")]),a._v(" "),e("h2",{attrs:{id:"磁盘容量"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#磁盘容量"}},[a._v("#")]),a._v(" 磁盘容量")]),a._v(" "),e("p",[a._v("磁盘容量是另一个值得讨论的话题。需要多大的磁盘容量取决于需要保留的消息数量。如 果服务器每天会收到 1TB 消息，并且保留 7 天，那么就需要 7TB 的存储空间，而且还要 为其他文件提供至少 10% 的额外空间。除此之外，还需要提供缓冲区，用于应付消息流量 的增长和波动。")]),a._v(" "),e("p",[a._v("在决定扩展 Kafka 集群规模时，存储容量是一个需要考虑的因素。通过让主题拥有多个分 区，集群的总流量可以被均衡到整个集群，而且如果单个 broker 无法支撑全部容量，可以 让其他 broker 提供可用的容量。存储容量的选择同时受到集群复制策略的影响")]),a._v(" "),e("h2",{attrs:{id:"内存"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#内存"}},[a._v("#")]),a._v(" 内存")]),a._v(" "),e("p",[a._v("除了磁盘性能外，服务器端可用的内存容量是影响客户端性能的主要因素。磁盘性能影响 生产者，而内存影响消费者。消费者一般从分区尾部读取消息，如果有生产者存在，就紧 跟在生产者后面。")]),a._v(" "),e("p",[a._v("在这种情况下，消费者读取的消息会直接存放在系统的页面缓存里，这 比从磁盘上重新读取要快得多。")]),a._v(" "),e("p",[a._v("运行 Kafka 的 JVM 不需要太大的内存，剩余的系统内存可以用作页面缓存，或者用来缓 存正在使用中的日志片段。这也就是为什么不建议把 Kafka 同其他重要的应用程序部署 在一起的原因，它们需要共享页面缓存，最终会降低 Kafka 消费者的性能。")]),a._v(" "),e("h2",{attrs:{id:"cpu"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#cpu"}},[a._v("#")]),a._v(" CPU")]),a._v(" "),e("p",[a._v("与磁盘和内存相比，Kafka 对计算处理能力的要求相对较低，不过它在一定程度上还是 会影响整体的性能。客户端为了优化网络和磁盘空间，会对消息进行压缩。服务器需要 对消息进行批量解压，设置偏移量，然后重新进行批量压缩，再保存到磁盘上。这就是 Kafka 对计算处理能力有所要求的地方。不过不管怎样，这都不应该成为选择硬件的主 要考虑因素。")]),a._v(" "),e("h2",{attrs:{id:"网络"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#网络"}},[a._v("#")]),a._v(" 网络")]),a._v(" "),e("p",[a._v("网络吞吐量决定了 Kafka 能够处理的最大数据流量。它和磁盘存储是制约 Kafka 扩展规模 的主要因素。Kafka 支持多个消费者，造成流入和流出的网络流量不平衡，从而让情况变 得更加复杂。对于给定的主题，一个生产者可能每秒钟写入 1MB 数据，但可能同时有多 个消费者瓜分网络流量。 。其他的操作，如集群复制 和镜像 也会占用网络流量。如果网络接口出现饱和，那么集群的复制出现延时就在所难免， 从而让集群不堪一击。")]),a._v(" "),e("p",[a._v("加群联系作者vx：xiaoda0423")]),a._v(" "),e("p",[a._v("仓库地址："),e("a",{attrs:{href:"https://webvueblog.github.io/JavaPlusDoc/",target:"_blank",rel:"noopener noreferrer"}},[a._v("https://webvueblog.github.io/JavaPlusDoc/"),e("OutboundLink")],1)])])}),[],!1,null,null,null);e.default=o.exports}}]);